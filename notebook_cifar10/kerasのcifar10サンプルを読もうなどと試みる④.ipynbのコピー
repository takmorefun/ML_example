{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kerasのcifar10サンプルを読もうなどと試みる④",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0uZxxFbUPqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d4c94bd-9d72-42e3-a61e-5919c7d411af"
      },
      "source": [
        "import keras as ks\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0xdNODwYKIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "61d0cc4d-3d29-43c3-f22a-81c3467823d7"
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = ks.utils.to_categorical(y_train, num_classes)\n",
        "y_test = ks.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YORwHstYVf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "158cc3e2-4918-4005-a7cd-bdedc52a7c51"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='RMSprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0722 11:32:52.129934 139950000236416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0722 11:32:52.147393 139950000236416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0722 11:32:52.149706 139950000236416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0722 11:32:52.178333 139950000236416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0722 11:32:52.180763 139950000236416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0722 11:32:52.191225 139950000236416 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0722 11:32:52.350470 139950000236416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0722 11:32:52.369779 139950000236416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 2, 2, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 505,770\n",
            "Trainable params: 505,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwgwLzL3cskO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "outputId": "19a4bd0a-4a78-4723-c287-8e87f66ebc18"
      },
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0722 11:32:52.564859 139950000236416 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 15s 300us/step - loss: 1.6989 - acc: 0.3795 - val_loss: 1.3890 - val_acc: 0.5086\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 1.2818 - acc: 0.5500 - val_loss: 1.2602 - val_acc: 0.5705\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.1371 - acc: 0.6105 - val_loss: 1.0399 - val_acc: 0.6549\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 1.0877 - acc: 0.6341 - val_loss: 1.0198 - val_acc: 0.6588\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 1.0956 - acc: 0.6376 - val_loss: 1.1211 - val_acc: 0.6263\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 1.0955 - acc: 0.6412 - val_loss: 1.0285 - val_acc: 0.6665\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.1033 - acc: 0.6430 - val_loss: 1.0469 - val_acc: 0.6648\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.1198 - acc: 0.6412 - val_loss: 1.0916 - val_acc: 0.6466\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 1.1606 - acc: 0.6330 - val_loss: 1.3449 - val_acc: 0.5603\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.1738 - acc: 0.6310 - val_loss: 1.1328 - val_acc: 0.6313\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.2429 - acc: 0.6167 - val_loss: 1.1013 - val_acc: 0.6192\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.2585 - acc: 0.6090 - val_loss: 1.1074 - val_acc: 0.6602\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.2952 - acc: 0.5994 - val_loss: 1.1022 - val_acc: 0.6498\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.3300 - acc: 0.5908 - val_loss: 2.2983 - val_acc: 0.4523\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.3759 - acc: 0.5789 - val_loss: 1.3505 - val_acc: 0.5581\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.4753 - acc: 0.5521 - val_loss: 2.1916 - val_acc: 0.4121\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.5376 - acc: 0.5372 - val_loss: 1.4431 - val_acc: 0.5642\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.6215 - acc: 0.5050 - val_loss: 1.2545 - val_acc: 0.5743\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.6900 - acc: 0.4849 - val_loss: 1.4724 - val_acc: 0.5398\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.6826 - acc: 0.4927 - val_loss: 1.5088 - val_acc: 0.5053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1CFQfnZeawP",
        "colab_type": "text"
      },
      "source": [
        "loss値がepoch6以降上がってaccuracyも下がってしまっている。\n",
        "もう少し考えてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39SwUvajeown",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "1be59e65-bd11-499a-d949-97ff7bc58f9e"
      },
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "model2.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.2))\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(512, activation='relu'))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(32, activation='relu'))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='RMSprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 2, 2, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                16416     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 517,386\n",
            "Trainable params: 517,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wondQSXAf-EM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "outputId": "c3064d02-0eca-49f7-b524-161a5a37bb20"
      },
      "source": [
        "history2 = model2.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.8423 - acc: 0.3248 - val_loss: 1.4461 - val_acc: 0.4725\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 1.3719 - acc: 0.5257 - val_loss: 1.1469 - val_acc: 0.6152\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 1.1845 - acc: 0.6057 - val_loss: 1.1241 - val_acc: 0.6165\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 1.1378 - acc: 0.6263 - val_loss: 1.1022 - val_acc: 0.6284\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 1.1653 - acc: 0.6277 - val_loss: 1.1415 - val_acc: 0.6318\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.1855 - acc: 0.6257 - val_loss: 1.0289 - val_acc: 0.6625\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.2287 - acc: 0.6153 - val_loss: 1.1064 - val_acc: 0.6123\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 13s 257us/step - loss: 1.2590 - acc: 0.6092 - val_loss: 1.0685 - val_acc: 0.6587\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 13s 257us/step - loss: 1.2666 - acc: 0.6049 - val_loss: 1.1585 - val_acc: 0.6616\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 13s 258us/step - loss: 1.3265 - acc: 0.5871 - val_loss: 1.5985 - val_acc: 0.5432\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 1.3683 - acc: 0.5738 - val_loss: 1.1740 - val_acc: 0.6186\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 13s 256us/step - loss: 1.4257 - acc: 0.5602 - val_loss: 1.3731 - val_acc: 0.5244\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 13s 260us/step - loss: 1.4772 - acc: 0.5426 - val_loss: 2.3791 - val_acc: 0.4354\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 13s 256us/step - loss: 1.5426 - acc: 0.5256 - val_loss: 1.5108 - val_acc: 0.4828\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 1.7178 - acc: 0.4738 - val_loss: 2.0987 - val_acc: 0.2698\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.7448 - acc: 0.4512 - val_loss: 1.5083 - val_acc: 0.5107\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.7853 - acc: 0.4337 - val_loss: 1.5823 - val_acc: 0.3901\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.9038 - acc: 0.4018 - val_loss: 1.7172 - val_acc: 0.3600\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 12s 250us/step - loss: 2.0222 - acc: 0.3707 - val_loss: 1.7772 - val_acc: 0.3887\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 2.0628 - acc: 0.3437 - val_loss: 1.4460 - val_acc: 0.4635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWMnzHMzhQas",
        "colab_type": "text"
      },
      "source": [
        "epoch4以降loss値増えaccuracyもepoch6以降増えない。何故なのか。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSNP0vfthgBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "outputId": "e29ac82d-ee3b-4dca-b19b-317c405ba9d4"
      },
      "source": [
        "model3 = Sequential()\n",
        "\n",
        "model3.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n",
        "model3.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model3.add(Dropout(0.2))\n",
        "\n",
        "model3.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model3.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model3.add(Dropout(0.2))\n",
        "\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(512, activation='relu'))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model3.summary()\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer='RMSprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0725 13:08:24.763044 140638557116288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0725 13:08:24.789097 140638557116288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0725 13:08:24.792517 140638557116288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0725 13:08:24.827064 140638557116288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0725 13:08:24.830220 140638557116288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0725 13:08:24.839853 140638557116288 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0725 13:08:24.977050 140638557116288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0725 13:08:25.005547 140638557116288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2p8Mgtph7W4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "outputId": "238fe139-ab60-4575-8cb2-ade38adf31a4"
      },
      "source": [
        "history3 = model3.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1141 - acc: 0.6512 - val_loss: 0.9109 - val_acc: 0.6953\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1351 - acc: 0.6438 - val_loss: 0.8630 - val_acc: 0.7124\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1541 - acc: 0.6393 - val_loss: 1.7450 - val_acc: 0.4401\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.1754 - acc: 0.6293 - val_loss: 1.1684 - val_acc: 0.5791\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.1846 - acc: 0.6233 - val_loss: 1.4133 - val_acc: 0.6423\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.1932 - acc: 0.6226 - val_loss: 1.0105 - val_acc: 0.6595\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.2040 - acc: 0.6164 - val_loss: 1.1784 - val_acc: 0.5860\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2079 - acc: 0.6160 - val_loss: 1.2174 - val_acc: 0.5780\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.2319 - acc: 0.6119 - val_loss: 1.2119 - val_acc: 0.6142\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2459 - acc: 0.6059 - val_loss: 1.0278 - val_acc: 0.6623\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2597 - acc: 0.5997 - val_loss: 1.2114 - val_acc: 0.6179\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2683 - acc: 0.5931 - val_loss: 1.0382 - val_acc: 0.6543\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.2729 - acc: 0.5946 - val_loss: 1.1556 - val_acc: 0.6120\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.2907 - acc: 0.5907 - val_loss: 2.0163 - val_acc: 0.5137\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.2921 - acc: 0.5854 - val_loss: 1.3074 - val_acc: 0.5377\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2759 - acc: 0.5895 - val_loss: 1.1275 - val_acc: 0.6236\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.2771 - acc: 0.5933 - val_loss: 1.1842 - val_acc: 0.6208\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3078 - acc: 0.5852 - val_loss: 1.1691 - val_acc: 0.5948\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.2978 - acc: 0.5837 - val_loss: 1.2402 - val_acc: 0.5942\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.3020 - acc: 0.5832 - val_loss: 1.2060 - val_acc: 0.6101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JlypwEAjcGe",
        "colab_type": "text"
      },
      "source": [
        "loss値は相変わらず途中から上がってしまったが最大で74%だった。こちらの方がいいのか。\n",
        "誤って再び実行したところ最初から7割近く出たが悪化した。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcwCo_77Pmx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer='AdaDelta',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IINMtGM4P35g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07d73184-8ca1-45c4-cb1f-74d17f04d43f"
      },
      "source": [
        "history3_2 = model3.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 13:08:51.966252 140638557116288 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 25s 504us/step - loss: 1.5293 - acc: 0.4459 - val_loss: 1.1883 - val_acc: 0.5754\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 23s 451us/step - loss: 1.0796 - acc: 0.6208 - val_loss: 1.0631 - val_acc: 0.6283\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 23s 452us/step - loss: 0.8995 - acc: 0.6830 - val_loss: 0.8366 - val_acc: 0.7173\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 23s 450us/step - loss: 0.7837 - acc: 0.7274 - val_loss: 0.7870 - val_acc: 0.7277\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.6950 - acc: 0.7571 - val_loss: 0.7751 - val_acc: 0.7381\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.6288 - acc: 0.7828 - val_loss: 0.7532 - val_acc: 0.7419\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 23s 455us/step - loss: 0.5757 - acc: 0.8007 - val_loss: 0.6798 - val_acc: 0.7704\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 23s 450us/step - loss: 0.5242 - acc: 0.8201 - val_loss: 0.7088 - val_acc: 0.7743\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.4799 - acc: 0.8341 - val_loss: 0.7007 - val_acc: 0.7763\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.4538 - acc: 0.8453 - val_loss: 0.7360 - val_acc: 0.7747\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.4264 - acc: 0.8542 - val_loss: 0.8655 - val_acc: 0.7510\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.4025 - acc: 0.8620 - val_loss: 0.6952 - val_acc: 0.7840\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.3915 - acc: 0.8680 - val_loss: 0.7871 - val_acc: 0.7790\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 22s 440us/step - loss: 0.3773 - acc: 0.8719 - val_loss: 0.7216 - val_acc: 0.7772\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 22s 442us/step - loss: 0.3672 - acc: 0.8777 - val_loss: 0.9234 - val_acc: 0.7789\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 24s 479us/step - loss: 0.3618 - acc: 0.8795 - val_loss: 0.8325 - val_acc: 0.7658\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 23s 469us/step - loss: 0.3571 - acc: 0.8835 - val_loss: 0.7851 - val_acc: 0.7875\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 24s 472us/step - loss: 0.3397 - acc: 0.8865 - val_loss: 0.9388 - val_acc: 0.7932\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 24s 472us/step - loss: 0.3456 - acc: 0.8864 - val_loss: 0.8742 - val_acc: 0.7894\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 24s 472us/step - loss: 0.3445 - acc: 0.8884 - val_loss: 0.8549 - val_acc: 0.7758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TBZaaYkRswr",
        "colab_type": "text"
      },
      "source": [
        "最後少し下がったが概ね良好。8割近く出た。\n",
        "epoch数100でやってみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZiApzFER2lm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ee148f2-04e3-4a02-d6a0-7591d8065c2a"
      },
      "source": [
        "history3_3 = model3.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=100,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "50000/50000 [==============================] - 23s 468us/step - loss: 0.3430 - acc: 0.8907 - val_loss: 0.8761 - val_acc: 0.7640\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 23s 454us/step - loss: 0.3388 - acc: 0.8910 - val_loss: 0.8849 - val_acc: 0.7879\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 23s 452us/step - loss: 0.3331 - acc: 0.8942 - val_loss: 0.9639 - val_acc: 0.7801\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.3390 - acc: 0.8925 - val_loss: 0.8489 - val_acc: 0.7845\n",
            "Epoch 5/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.3309 - acc: 0.8955 - val_loss: 0.8084 - val_acc: 0.7745\n",
            "Epoch 6/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.3369 - acc: 0.8935 - val_loss: 0.9656 - val_acc: 0.7968\n",
            "Epoch 7/100\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.3368 - acc: 0.8952 - val_loss: 0.9240 - val_acc: 0.7907\n",
            "Epoch 8/100\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.3370 - acc: 0.8946 - val_loss: 1.0206 - val_acc: 0.7871\n",
            "Epoch 9/100\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.3407 - acc: 0.8939 - val_loss: 1.0554 - val_acc: 0.7856\n",
            "Epoch 10/100\n",
            "50000/50000 [==============================] - 23s 466us/step - loss: 0.3436 - acc: 0.8939 - val_loss: 0.9446 - val_acc: 0.7898\n",
            "Epoch 11/100\n",
            "50000/50000 [==============================] - 23s 459us/step - loss: 0.3328 - acc: 0.8976 - val_loss: 0.8955 - val_acc: 0.7834\n",
            "Epoch 12/100\n",
            "50000/50000 [==============================] - 23s 465us/step - loss: 0.3429 - acc: 0.8955 - val_loss: 0.9407 - val_acc: 0.7827\n",
            "Epoch 13/100\n",
            "50000/50000 [==============================] - 23s 459us/step - loss: 0.3482 - acc: 0.8966 - val_loss: 1.0710 - val_acc: 0.7898\n",
            "Epoch 14/100\n",
            "50000/50000 [==============================] - 23s 459us/step - loss: 0.3415 - acc: 0.8980 - val_loss: 0.9467 - val_acc: 0.7694\n",
            "Epoch 15/100\n",
            "50000/50000 [==============================] - 23s 458us/step - loss: 0.3483 - acc: 0.8950 - val_loss: 1.0095 - val_acc: 0.7769\n",
            "Epoch 16/100\n",
            "50000/50000 [==============================] - 23s 459us/step - loss: 0.3603 - acc: 0.8936 - val_loss: 1.1747 - val_acc: 0.7848\n",
            "Epoch 17/100\n",
            "50000/50000 [==============================] - 23s 460us/step - loss: 0.3499 - acc: 0.8963 - val_loss: 0.8874 - val_acc: 0.7812\n",
            "Epoch 18/100\n",
            "50000/50000 [==============================] - 23s 460us/step - loss: 0.3642 - acc: 0.8912 - val_loss: 1.0141 - val_acc: 0.7880\n",
            "Epoch 19/100\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.3652 - acc: 0.8947 - val_loss: 0.8301 - val_acc: 0.7804\n",
            "Epoch 20/100\n",
            "50000/50000 [==============================] - 23s 458us/step - loss: 0.3564 - acc: 0.8931 - val_loss: 0.9827 - val_acc: 0.7865\n",
            "Epoch 21/100\n",
            "50000/50000 [==============================] - 23s 457us/step - loss: 0.3609 - acc: 0.8931 - val_loss: 0.8312 - val_acc: 0.7508\n",
            "Epoch 22/100\n",
            "50000/50000 [==============================] - 23s 456us/step - loss: 0.3680 - acc: 0.8932 - val_loss: 0.9859 - val_acc: 0.7882\n",
            "Epoch 23/100\n",
            "50000/50000 [==============================] - 23s 456us/step - loss: 0.3725 - acc: 0.8932 - val_loss: 0.8787 - val_acc: 0.7447\n",
            "Epoch 24/100\n",
            "50000/50000 [==============================] - 23s 457us/step - loss: 0.3731 - acc: 0.8891 - val_loss: 0.8798 - val_acc: 0.7846\n",
            "Epoch 25/100\n",
            "50000/50000 [==============================] - 23s 458us/step - loss: 0.3782 - acc: 0.8903 - val_loss: 0.9217 - val_acc: 0.7568\n",
            "Epoch 26/100\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 0.3691 - acc: 0.8915 - val_loss: 0.9521 - val_acc: 0.7823\n",
            "Epoch 27/100\n",
            "50000/50000 [==============================] - 23s 455us/step - loss: 0.3844 - acc: 0.8884 - val_loss: 0.9808 - val_acc: 0.7758\n",
            "Epoch 28/100\n",
            "50000/50000 [==============================] - 22s 440us/step - loss: 0.3892 - acc: 0.8891 - val_loss: 0.8509 - val_acc: 0.7773\n",
            "Epoch 29/100\n",
            "50000/50000 [==============================] - 24s 483us/step - loss: 0.3764 - acc: 0.8924 - val_loss: 1.2209 - val_acc: 0.7736\n",
            "Epoch 30/100\n",
            "50000/50000 [==============================] - 23s 470us/step - loss: 0.3920 - acc: 0.8882 - val_loss: 0.8725 - val_acc: 0.7673\n",
            "Epoch 31/100\n",
            "50000/50000 [==============================] - 23s 470us/step - loss: 0.3958 - acc: 0.8871 - val_loss: 0.9715 - val_acc: 0.7787\n",
            "Epoch 32/100\n",
            "50000/50000 [==============================] - 23s 469us/step - loss: 0.4010 - acc: 0.8858 - val_loss: 0.9578 - val_acc: 0.7520\n",
            "Epoch 33/100\n",
            "50000/50000 [==============================] - 23s 466us/step - loss: 0.3922 - acc: 0.8868 - val_loss: 0.9544 - val_acc: 0.7804\n",
            "Epoch 34/100\n",
            "50000/50000 [==============================] - 23s 466us/step - loss: 0.3986 - acc: 0.8854 - val_loss: 1.1489 - val_acc: 0.7801\n",
            "Epoch 35/100\n",
            "50000/50000 [==============================] - 23s 466us/step - loss: 0.3946 - acc: 0.8871 - val_loss: 0.8837 - val_acc: 0.7365\n",
            "Epoch 36/100\n",
            "50000/50000 [==============================] - 23s 465us/step - loss: 0.4054 - acc: 0.8853 - val_loss: 1.2489 - val_acc: 0.7690\n",
            "Epoch 37/100\n",
            "50000/50000 [==============================] - 23s 465us/step - loss: 0.4095 - acc: 0.8823 - val_loss: 0.9575 - val_acc: 0.7459\n",
            "Epoch 38/100\n",
            "50000/50000 [==============================] - 23s 465us/step - loss: 0.4009 - acc: 0.8852 - val_loss: 1.0775 - val_acc: 0.7823\n",
            "Epoch 39/100\n",
            "50000/50000 [==============================] - 23s 470us/step - loss: 0.4220 - acc: 0.8819 - val_loss: 1.0662 - val_acc: 0.7821\n",
            "Epoch 40/100\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.4023 - acc: 0.8865 - val_loss: 0.8411 - val_acc: 0.7485\n",
            "Epoch 41/100\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.4131 - acc: 0.8845 - val_loss: 1.1185 - val_acc: 0.7813\n",
            "Epoch 42/100\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.4167 - acc: 0.8847 - val_loss: 0.8852 - val_acc: 0.7716\n",
            "Epoch 43/100\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 0.4079 - acc: 0.8863 - val_loss: 1.0279 - val_acc: 0.7733\n",
            "Epoch 44/100\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 0.4158 - acc: 0.8845 - val_loss: 0.9406 - val_acc: 0.7645\n",
            "Epoch 45/100\n",
            "50000/50000 [==============================] - 23s 451us/step - loss: 0.4133 - acc: 0.8831 - val_loss: 1.1474 - val_acc: 0.7771\n",
            "Epoch 46/100\n",
            "50000/50000 [==============================] - 22s 441us/step - loss: 0.4260 - acc: 0.8821 - val_loss: 1.0891 - val_acc: 0.7539\n",
            "Epoch 47/100\n",
            "50000/50000 [==============================] - 23s 465us/step - loss: 0.4383 - acc: 0.8791 - val_loss: 0.9831 - val_acc: 0.7654\n",
            "Epoch 48/100\n",
            "50000/50000 [==============================] - 25s 496us/step - loss: 0.4310 - acc: 0.8799 - val_loss: 0.9070 - val_acc: 0.7701\n",
            "Epoch 49/100\n",
            "50000/50000 [==============================] - 24s 476us/step - loss: 0.4297 - acc: 0.8812 - val_loss: 0.9843 - val_acc: 0.7777\n",
            "Epoch 50/100\n",
            "50000/50000 [==============================] - 24s 473us/step - loss: 0.4268 - acc: 0.8847 - val_loss: 1.1753 - val_acc: 0.7818\n",
            "Epoch 51/100\n",
            "50000/50000 [==============================] - 24s 471us/step - loss: 0.4443 - acc: 0.8784 - val_loss: 0.8716 - val_acc: 0.7566\n",
            "Epoch 52/100\n",
            "50000/50000 [==============================] - 24s 477us/step - loss: 0.4464 - acc: 0.8782 - val_loss: 1.0320 - val_acc: 0.7673\n",
            "Epoch 53/100\n",
            "50000/50000 [==============================] - 24s 472us/step - loss: 0.4406 - acc: 0.8787 - val_loss: 1.1511 - val_acc: 0.7810\n",
            "Epoch 54/100\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.4426 - acc: 0.8788 - val_loss: 0.9094 - val_acc: 0.7276\n",
            "Epoch 55/100\n",
            "50000/50000 [==============================] - 23s 465us/step - loss: 0.4436 - acc: 0.8771 - val_loss: 0.9593 - val_acc: 0.7545\n",
            "Epoch 56/100\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.4320 - acc: 0.8789 - val_loss: 0.9404 - val_acc: 0.7572\n",
            "Epoch 57/100\n",
            "50000/50000 [==============================] - 23s 466us/step - loss: 0.4510 - acc: 0.8744 - val_loss: 1.1483 - val_acc: 0.7617\n",
            "Epoch 58/100\n",
            "50000/50000 [==============================] - 23s 466us/step - loss: 0.4454 - acc: 0.8794 - val_loss: 0.9499 - val_acc: 0.7732\n",
            "Epoch 59/100\n",
            "50000/50000 [==============================] - 23s 463us/step - loss: 0.4411 - acc: 0.8810 - val_loss: 0.9921 - val_acc: 0.7192\n",
            "Epoch 60/100\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 0.4552 - acc: 0.8747 - val_loss: 1.1362 - val_acc: 0.7707\n",
            "Epoch 61/100\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.4432 - acc: 0.8778 - val_loss: 0.9474 - val_acc: 0.7567\n",
            "Epoch 62/100\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.4560 - acc: 0.8755 - val_loss: 1.1655 - val_acc: 0.7529\n",
            "Epoch 63/100\n",
            "50000/50000 [==============================] - 27s 532us/step - loss: 0.4651 - acc: 0.8729 - val_loss: 1.0988 - val_acc: 0.7633\n",
            "Epoch 64/100\n",
            "50000/50000 [==============================] - 24s 471us/step - loss: 0.4531 - acc: 0.8743 - val_loss: 1.0110 - val_acc: 0.7681\n",
            "Epoch 65/100\n",
            "50000/50000 [==============================] - 24s 477us/step - loss: 0.4655 - acc: 0.8741 - val_loss: 1.3374 - val_acc: 0.7778\n",
            "Epoch 66/100\n",
            "50000/50000 [==============================] - 24s 477us/step - loss: 0.4777 - acc: 0.8695 - val_loss: 1.3591 - val_acc: 0.7758\n",
            "Epoch 67/100\n",
            "50000/50000 [==============================] - 24s 473us/step - loss: 0.4824 - acc: 0.8695 - val_loss: 1.3923 - val_acc: 0.7580\n",
            "Epoch 68/100\n",
            "50000/50000 [==============================] - 24s 473us/step - loss: 0.4759 - acc: 0.8715 - val_loss: 1.1888 - val_acc: 0.7745\n",
            "Epoch 69/100\n",
            "50000/50000 [==============================] - 24s 474us/step - loss: 0.4643 - acc: 0.8715 - val_loss: 1.0101 - val_acc: 0.7782\n",
            "Epoch 70/100\n",
            "50000/50000 [==============================] - 24s 473us/step - loss: 0.4910 - acc: 0.8690 - val_loss: 1.0918 - val_acc: 0.7356\n",
            "Epoch 71/100\n",
            "50000/50000 [==============================] - 24s 474us/step - loss: 0.4870 - acc: 0.8699 - val_loss: 0.9684 - val_acc: 0.6849\n",
            "Epoch 72/100\n",
            "50000/50000 [==============================] - 24s 471us/step - loss: 0.4813 - acc: 0.8708 - val_loss: 1.1087 - val_acc: 0.7562\n",
            "Epoch 73/100\n",
            "50000/50000 [==============================] - 24s 474us/step - loss: 0.4817 - acc: 0.8713 - val_loss: 0.9340 - val_acc: 0.7479\n",
            "Epoch 74/100\n",
            "50000/50000 [==============================] - 24s 474us/step - loss: 0.4840 - acc: 0.8693 - val_loss: 1.1484 - val_acc: 0.7481\n",
            "Epoch 75/100\n",
            "50000/50000 [==============================] - 24s 471us/step - loss: 0.4877 - acc: 0.8679 - val_loss: 1.0755 - val_acc: 0.6534\n",
            "Epoch 76/100\n",
            "50000/50000 [==============================] - 23s 468us/step - loss: 0.4772 - acc: 0.8714 - val_loss: 0.9778 - val_acc: 0.7529\n",
            "Epoch 77/100\n",
            "50000/50000 [==============================] - 23s 470us/step - loss: 0.5052 - acc: 0.8670 - val_loss: 0.8833 - val_acc: 0.7640\n",
            "Epoch 78/100\n",
            "50000/50000 [==============================] - 23s 469us/step - loss: 0.4825 - acc: 0.8682 - val_loss: 0.9811 - val_acc: 0.7416\n",
            "Epoch 79/100\n",
            "50000/50000 [==============================] - 24s 473us/step - loss: 0.4938 - acc: 0.8663 - val_loss: 1.0207 - val_acc: 0.7768\n",
            "Epoch 80/100\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.5053 - acc: 0.8641 - val_loss: 1.4684 - val_acc: 0.7607\n",
            "Epoch 81/100\n",
            "50000/50000 [==============================] - 23s 468us/step - loss: 0.5049 - acc: 0.8636 - val_loss: 1.0868 - val_acc: 0.7787\n",
            "Epoch 82/100\n",
            "50000/50000 [==============================] - 27s 530us/step - loss: 0.4951 - acc: 0.8652 - val_loss: 1.1708 - val_acc: 0.7350\n",
            "Epoch 83/100\n",
            "50000/50000 [==============================] - 24s 472us/step - loss: 0.5149 - acc: 0.8613 - val_loss: 1.3379 - val_acc: 0.7634\n",
            "Epoch 84/100\n",
            "50000/50000 [==============================] - 24s 477us/step - loss: 0.5083 - acc: 0.8640 - val_loss: 1.0921 - val_acc: 0.7659\n",
            "Epoch 85/100\n",
            "50000/50000 [==============================] - 24s 471us/step - loss: 0.5144 - acc: 0.8627 - val_loss: 1.1823 - val_acc: 0.7780\n",
            "Epoch 86/100\n",
            "50000/50000 [==============================] - 24s 473us/step - loss: 0.4960 - acc: 0.8650 - val_loss: 1.0413 - val_acc: 0.7615\n",
            "Epoch 87/100\n",
            "50000/50000 [==============================] - 24s 473us/step - loss: 0.5128 - acc: 0.8635 - val_loss: 1.0313 - val_acc: 0.7496\n",
            "Epoch 88/100\n",
            "50000/50000 [==============================] - 23s 470us/step - loss: 0.5129 - acc: 0.8628 - val_loss: 1.0367 - val_acc: 0.7723\n",
            "Epoch 89/100\n",
            "50000/50000 [==============================] - 24s 474us/step - loss: 0.5229 - acc: 0.8603 - val_loss: 1.8977 - val_acc: 0.7639\n",
            "Epoch 90/100\n",
            "50000/50000 [==============================] - 23s 467us/step - loss: 0.5251 - acc: 0.8577 - val_loss: 1.1790 - val_acc: 0.7625\n",
            "Epoch 91/100\n",
            "50000/50000 [==============================] - 23s 463us/step - loss: 0.5215 - acc: 0.8623 - val_loss: 0.8869 - val_acc: 0.7604\n",
            "Epoch 92/100\n",
            "50000/50000 [==============================] - 24s 470us/step - loss: 0.5325 - acc: 0.8587 - val_loss: 1.1120 - val_acc: 0.7661\n",
            "Epoch 93/100\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 0.5252 - acc: 0.8582 - val_loss: 0.9907 - val_acc: 0.7497\n",
            "Epoch 94/100\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 0.5248 - acc: 0.8603 - val_loss: 0.9568 - val_acc: 0.7472\n",
            "Epoch 95/100\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.5132 - acc: 0.8633 - val_loss: 1.2058 - val_acc: 0.7786\n",
            "Epoch 96/100\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.5263 - acc: 0.8618 - val_loss: 1.0200 - val_acc: 0.7667\n",
            "Epoch 97/100\n",
            "50000/50000 [==============================] - 23s 465us/step - loss: 0.5380 - acc: 0.8564 - val_loss: 0.9431 - val_acc: 0.7340\n",
            "Epoch 98/100\n",
            "50000/50000 [==============================] - 23s 458us/step - loss: 0.5443 - acc: 0.8565 - val_loss: 0.9787 - val_acc: 0.6957\n",
            "Epoch 99/100\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 0.5338 - acc: 0.8577 - val_loss: 1.4526 - val_acc: 0.7669\n",
            "Epoch 100/100\n",
            "50000/50000 [==============================] - 28s 556us/step - loss: 0.5376 - acc: 0.8553 - val_loss: 0.9806 - val_acc: 0.7574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpY5mbBfa5re",
        "colab_type": "text"
      },
      "source": [
        "最大でほぼ8割出たがloss値は徐々に上がってしまった。\n",
        "学習率を下げる手法を用いてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GFmxBJwbb7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ef08f7f-958b-403e-ba89-dee20e3164f1"
      },
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def step_decay(epoch):\n",
        "    x = 0.1\n",
        "    if epoch >= 20: x = 0.01\n",
        "    if epoch >= 50: x = 0.001\n",
        "    if epoch >= 80: x = 0.0001\n",
        "    return x\n",
        "Ir_decay = LearningRateScheduler(step_decay)\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer='AdaDelta',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "history3_4 = model3.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=100,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[Ir_decay])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "50000/50000 [==============================] - 23s 468us/step - loss: 0.2887 - acc: 0.9207 - val_loss: 0.9832 - val_acc: 0.7959\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 23s 453us/step - loss: 0.2308 - acc: 0.9405 - val_loss: 1.1172 - val_acc: 0.8040\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 23s 451us/step - loss: 0.2230 - acc: 0.9410 - val_loss: 1.0118 - val_acc: 0.7972\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.2136 - acc: 0.9462 - val_loss: 1.0858 - val_acc: 0.7991\n",
            "Epoch 5/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.2104 - acc: 0.9454 - val_loss: 0.9618 - val_acc: 0.7979\n",
            "Epoch 6/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.2070 - acc: 0.9470 - val_loss: 1.0342 - val_acc: 0.7995\n",
            "Epoch 7/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.2048 - acc: 0.9460 - val_loss: 0.9975 - val_acc: 0.8037\n",
            "Epoch 8/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.1893 - acc: 0.9502 - val_loss: 1.0134 - val_acc: 0.7971\n",
            "Epoch 9/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.1986 - acc: 0.9491 - val_loss: 1.0565 - val_acc: 0.8030\n",
            "Epoch 10/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.2003 - acc: 0.9481 - val_loss: 1.0452 - val_acc: 0.8027\n",
            "Epoch 11/100\n",
            "50000/50000 [==============================] - 23s 451us/step - loss: 0.2056 - acc: 0.9477 - val_loss: 1.0128 - val_acc: 0.8015\n",
            "Epoch 12/100\n",
            "50000/50000 [==============================] - 23s 451us/step - loss: 0.1967 - acc: 0.9486 - val_loss: 0.9861 - val_acc: 0.8000\n",
            "Epoch 13/100\n",
            "50000/50000 [==============================] - 22s 442us/step - loss: 0.1917 - acc: 0.9511 - val_loss: 0.9748 - val_acc: 0.8015\n",
            "Epoch 14/100\n",
            "50000/50000 [==============================] - 22s 443us/step - loss: 0.1943 - acc: 0.9494 - val_loss: 0.9869 - val_acc: 0.8008\n",
            "Epoch 15/100\n",
            "50000/50000 [==============================] - 22s 445us/step - loss: 0.1931 - acc: 0.9501 - val_loss: 0.9728 - val_acc: 0.8030\n",
            "Epoch 16/100\n",
            "50000/50000 [==============================] - 22s 444us/step - loss: 0.1986 - acc: 0.9484 - val_loss: 0.9393 - val_acc: 0.7929\n",
            "Epoch 17/100\n",
            "50000/50000 [==============================] - 22s 444us/step - loss: 0.1950 - acc: 0.9497 - val_loss: 0.9538 - val_acc: 0.7984\n",
            "Epoch 18/100\n",
            "50000/50000 [==============================] - 22s 440us/step - loss: 0.1939 - acc: 0.9511 - val_loss: 1.0075 - val_acc: 0.8015\n",
            "Epoch 19/100\n",
            "50000/50000 [==============================] - 24s 474us/step - loss: 0.1988 - acc: 0.9492 - val_loss: 0.9313 - val_acc: 0.7952\n",
            "Epoch 20/100\n",
            "50000/50000 [==============================] - 23s 454us/step - loss: 0.1958 - acc: 0.9502 - val_loss: 0.9533 - val_acc: 0.7984\n",
            "Epoch 21/100\n",
            "50000/50000 [==============================] - 23s 460us/step - loss: 0.1842 - acc: 0.9536 - val_loss: 1.0032 - val_acc: 0.8049\n",
            "Epoch 22/100\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.1824 - acc: 0.9545 - val_loss: 0.9965 - val_acc: 0.8020\n",
            "Epoch 23/100\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.1808 - acc: 0.9554 - val_loss: 0.9784 - val_acc: 0.8029\n",
            "Epoch 24/100\n",
            "50000/50000 [==============================] - 23s 460us/step - loss: 0.1786 - acc: 0.9564 - val_loss: 0.9670 - val_acc: 0.8019\n",
            "Epoch 25/100\n",
            "50000/50000 [==============================] - 23s 467us/step - loss: 0.1742 - acc: 0.9547 - val_loss: 1.0018 - val_acc: 0.8050\n",
            "Epoch 26/100\n",
            "50000/50000 [==============================] - 23s 460us/step - loss: 0.1742 - acc: 0.9562 - val_loss: 0.9861 - val_acc: 0.8023\n",
            "Epoch 27/100\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.1679 - acc: 0.9565 - val_loss: 0.9807 - val_acc: 0.8031\n",
            "Epoch 28/100\n",
            "50000/50000 [==============================] - 23s 460us/step - loss: 0.1692 - acc: 0.9570 - val_loss: 0.9950 - val_acc: 0.8034\n",
            "Epoch 29/100\n",
            "50000/50000 [==============================] - 23s 463us/step - loss: 0.1764 - acc: 0.9562 - val_loss: 0.9966 - val_acc: 0.8048\n",
            "Epoch 30/100\n",
            "50000/50000 [==============================] - 23s 459us/step - loss: 0.1701 - acc: 0.9560 - val_loss: 0.9893 - val_acc: 0.8018\n",
            "Epoch 31/100\n",
            "50000/50000 [==============================] - 23s 458us/step - loss: 0.1659 - acc: 0.9582 - val_loss: 0.9852 - val_acc: 0.8040\n",
            "Epoch 32/100\n",
            "50000/50000 [==============================] - 23s 455us/step - loss: 0.1721 - acc: 0.9579 - val_loss: 0.9907 - val_acc: 0.8045\n",
            "Epoch 33/100\n",
            "50000/50000 [==============================] - 23s 456us/step - loss: 0.1740 - acc: 0.9556 - val_loss: 0.9862 - val_acc: 0.8054\n",
            "Epoch 34/100\n",
            "50000/50000 [==============================] - 23s 455us/step - loss: 0.1770 - acc: 0.9555 - val_loss: 1.0058 - val_acc: 0.8051\n",
            "Epoch 35/100\n",
            "50000/50000 [==============================] - 23s 457us/step - loss: 0.1786 - acc: 0.9561 - val_loss: 0.9686 - val_acc: 0.8036\n",
            "Epoch 36/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1763 - acc: 0.9566 - val_loss: 0.9826 - val_acc: 0.8043\n",
            "Epoch 37/100\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 0.1675 - acc: 0.9578 - val_loss: 0.9726 - val_acc: 0.8035\n",
            "Epoch 38/100\n",
            "50000/50000 [==============================] - 25s 497us/step - loss: 0.1716 - acc: 0.9569 - val_loss: 1.0086 - val_acc: 0.8056\n",
            "Epoch 39/100\n",
            "50000/50000 [==============================] - 24s 470us/step - loss: 0.1759 - acc: 0.9554 - val_loss: 0.9819 - val_acc: 0.8037\n",
            "Epoch 40/100\n",
            "50000/50000 [==============================] - 23s 465us/step - loss: 0.1720 - acc: 0.9564 - val_loss: 0.9883 - val_acc: 0.8038\n",
            "Epoch 41/100\n",
            "50000/50000 [==============================] - 23s 466us/step - loss: 0.1716 - acc: 0.9573 - val_loss: 0.9799 - val_acc: 0.8036\n",
            "Epoch 42/100\n",
            "50000/50000 [==============================] - 23s 467us/step - loss: 0.1714 - acc: 0.9564 - val_loss: 1.0039 - val_acc: 0.8041\n",
            "Epoch 43/100\n",
            "50000/50000 [==============================] - 23s 463us/step - loss: 0.1654 - acc: 0.9579 - val_loss: 0.9913 - val_acc: 0.8058\n",
            "Epoch 44/100\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.1693 - acc: 0.9565 - val_loss: 0.9938 - val_acc: 0.8040\n",
            "Epoch 45/100\n",
            "50000/50000 [==============================] - 23s 465us/step - loss: 0.1696 - acc: 0.9571 - val_loss: 0.9813 - val_acc: 0.8035\n",
            "Epoch 46/100\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.1779 - acc: 0.9565 - val_loss: 0.9841 - val_acc: 0.8037\n",
            "Epoch 47/100\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.1742 - acc: 0.9570 - val_loss: 0.9911 - val_acc: 0.8050\n",
            "Epoch 48/100\n",
            "50000/50000 [==============================] - 23s 463us/step - loss: 0.1747 - acc: 0.9571 - val_loss: 0.9693 - val_acc: 0.8043\n",
            "Epoch 49/100\n",
            "50000/50000 [==============================] - 23s 460us/step - loss: 0.1726 - acc: 0.9562 - val_loss: 0.9702 - val_acc: 0.8036\n",
            "Epoch 50/100\n",
            "50000/50000 [==============================] - 23s 460us/step - loss: 0.1721 - acc: 0.9561 - val_loss: 0.9747 - val_acc: 0.8049\n",
            "Epoch 51/100\n",
            "50000/50000 [==============================] - 23s 460us/step - loss: 0.1671 - acc: 0.9576 - val_loss: 0.9788 - val_acc: 0.8039\n",
            "Epoch 52/100\n",
            "50000/50000 [==============================] - 23s 468us/step - loss: 0.1702 - acc: 0.9577 - val_loss: 0.9887 - val_acc: 0.8045\n",
            "Epoch 53/100\n",
            "50000/50000 [==============================] - 23s 456us/step - loss: 0.1652 - acc: 0.9589 - val_loss: 0.9881 - val_acc: 0.8038\n",
            "Epoch 54/100\n",
            "50000/50000 [==============================] - 22s 438us/step - loss: 0.1705 - acc: 0.9559 - val_loss: 0.9830 - val_acc: 0.8040\n",
            "Epoch 55/100\n",
            "50000/50000 [==============================] - 26s 513us/step - loss: 0.1656 - acc: 0.9577 - val_loss: 0.9893 - val_acc: 0.8038\n",
            "Epoch 56/100\n",
            "50000/50000 [==============================] - 24s 475us/step - loss: 0.1602 - acc: 0.9574 - val_loss: 0.9971 - val_acc: 0.8049\n",
            "Epoch 57/100\n",
            "50000/50000 [==============================] - 23s 469us/step - loss: 0.1670 - acc: 0.9583 - val_loss: 0.9989 - val_acc: 0.8049\n",
            "Epoch 58/100\n",
            "50000/50000 [==============================] - 23s 463us/step - loss: 0.1707 - acc: 0.9566 - val_loss: 0.9914 - val_acc: 0.8043\n",
            "Epoch 59/100\n",
            "50000/50000 [==============================] - 23s 465us/step - loss: 0.1713 - acc: 0.9572 - val_loss: 0.9893 - val_acc: 0.8037\n",
            "Epoch 60/100\n",
            "50000/50000 [==============================] - 23s 463us/step - loss: 0.1719 - acc: 0.9572 - val_loss: 0.9926 - val_acc: 0.8040\n",
            "Epoch 61/100\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 0.1748 - acc: 0.9568 - val_loss: 0.9919 - val_acc: 0.8039\n",
            "Epoch 62/100\n",
            "50000/50000 [==============================] - 23s 463us/step - loss: 0.1770 - acc: 0.9552 - val_loss: 0.9906 - val_acc: 0.8033\n",
            "Epoch 63/100\n",
            "50000/50000 [==============================] - 23s 463us/step - loss: 0.1650 - acc: 0.9571 - val_loss: 0.9982 - val_acc: 0.8040\n",
            "Epoch 64/100\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.1624 - acc: 0.9590 - val_loss: 1.0005 - val_acc: 0.8044\n",
            "Epoch 65/100\n",
            "50000/50000 [==============================] - 23s 466us/step - loss: 0.1642 - acc: 0.9580 - val_loss: 0.9951 - val_acc: 0.8037\n",
            "Epoch 66/100\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.1757 - acc: 0.9552 - val_loss: 0.9880 - val_acc: 0.8031\n",
            "Epoch 67/100\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 0.1760 - acc: 0.9565 - val_loss: 0.9887 - val_acc: 0.8035\n",
            "Epoch 68/100\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 0.1669 - acc: 0.9578 - val_loss: 0.9903 - val_acc: 0.8037\n",
            "Epoch 69/100\n",
            "50000/50000 [==============================] - 23s 462us/step - loss: 0.1630 - acc: 0.9576 - val_loss: 0.9964 - val_acc: 0.8035\n",
            "Epoch 70/100\n",
            "50000/50000 [==============================] - 23s 460us/step - loss: 0.1708 - acc: 0.9573 - val_loss: 0.9975 - val_acc: 0.8041\n",
            "Epoch 71/100\n",
            "50000/50000 [==============================] - 27s 531us/step - loss: 0.1677 - acc: 0.9575 - val_loss: 0.9972 - val_acc: 0.8039\n",
            "Epoch 72/100\n",
            "50000/50000 [==============================] - 24s 474us/step - loss: 0.1658 - acc: 0.9583 - val_loss: 0.9977 - val_acc: 0.8041\n",
            "Epoch 73/100\n",
            "50000/50000 [==============================] - 23s 469us/step - loss: 0.1781 - acc: 0.9576 - val_loss: 0.9943 - val_acc: 0.8045\n",
            "Epoch 74/100\n",
            "50000/50000 [==============================] - 23s 465us/step - loss: 0.1699 - acc: 0.9573 - val_loss: 0.9884 - val_acc: 0.8034\n",
            "Epoch 75/100\n",
            "50000/50000 [==============================] - 23s 466us/step - loss: 0.1683 - acc: 0.9569 - val_loss: 0.9931 - val_acc: 0.8035\n",
            "Epoch 76/100\n",
            "50000/50000 [==============================] - 23s 468us/step - loss: 0.1738 - acc: 0.9569 - val_loss: 0.9899 - val_acc: 0.8039\n",
            "Epoch 77/100\n",
            "50000/50000 [==============================] - 23s 466us/step - loss: 0.1755 - acc: 0.9581 - val_loss: 0.9901 - val_acc: 0.8044\n",
            "Epoch 78/100\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.1737 - acc: 0.9564 - val_loss: 0.9893 - val_acc: 0.8038\n",
            "Epoch 79/100\n",
            "50000/50000 [==============================] - 24s 473us/step - loss: 0.1633 - acc: 0.9586 - val_loss: 0.9925 - val_acc: 0.8044\n",
            "Epoch 80/100\n",
            "50000/50000 [==============================] - 23s 468us/step - loss: 0.1626 - acc: 0.9579 - val_loss: 0.9939 - val_acc: 0.8041\n",
            "Epoch 81/100\n",
            "50000/50000 [==============================] - 23s 468us/step - loss: 0.1637 - acc: 0.9575 - val_loss: 0.9936 - val_acc: 0.8042\n",
            "Epoch 82/100\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.1694 - acc: 0.9576 - val_loss: 0.9931 - val_acc: 0.8046\n",
            "Epoch 83/100\n",
            "50000/50000 [==============================] - 23s 461us/step - loss: 0.1644 - acc: 0.9580 - val_loss: 0.9929 - val_acc: 0.8043\n",
            "Epoch 84/100\n",
            "50000/50000 [==============================] - 23s 459us/step - loss: 0.1685 - acc: 0.9581 - val_loss: 0.9927 - val_acc: 0.8042\n",
            "Epoch 85/100\n",
            "50000/50000 [==============================] - 23s 459us/step - loss: 0.1638 - acc: 0.9576 - val_loss: 0.9922 - val_acc: 0.8043\n",
            "Epoch 86/100\n",
            "50000/50000 [==============================] - 23s 460us/step - loss: 0.1731 - acc: 0.9565 - val_loss: 0.9912 - val_acc: 0.8045\n",
            "Epoch 87/100\n",
            "50000/50000 [==============================] - 23s 459us/step - loss: 0.1704 - acc: 0.9572 - val_loss: 0.9903 - val_acc: 0.8042\n",
            "Epoch 88/100\n",
            "50000/50000 [==============================] - 23s 459us/step - loss: 0.1679 - acc: 0.9575 - val_loss: 0.9907 - val_acc: 0.8044\n",
            "Epoch 89/100\n",
            "50000/50000 [==============================] - 23s 453us/step - loss: 0.1683 - acc: 0.9576 - val_loss: 0.9908 - val_acc: 0.8043\n",
            "Epoch 90/100\n",
            "50000/50000 [==============================] - 22s 439us/step - loss: 0.1709 - acc: 0.9568 - val_loss: 0.9900 - val_acc: 0.8044\n",
            "Epoch 91/100\n",
            "50000/50000 [==============================] - 28s 552us/step - loss: 0.1669 - acc: 0.9573 - val_loss: 0.9903 - val_acc: 0.8042\n",
            "Epoch 92/100\n",
            "50000/50000 [==============================] - 24s 471us/step - loss: 0.1639 - acc: 0.9575 - val_loss: 0.9905 - val_acc: 0.8042\n",
            "Epoch 93/100\n",
            "50000/50000 [==============================] - 23s 467us/step - loss: 0.1633 - acc: 0.9583 - val_loss: 0.9907 - val_acc: 0.8042\n",
            "Epoch 94/100\n",
            "50000/50000 [==============================] - 23s 465us/step - loss: 0.1725 - acc: 0.9570 - val_loss: 0.9904 - val_acc: 0.8044\n",
            "Epoch 95/100\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.1728 - acc: 0.9562 - val_loss: 0.9897 - val_acc: 0.8043\n",
            "Epoch 96/100\n",
            "50000/50000 [==============================] - 23s 463us/step - loss: 0.1679 - acc: 0.9574 - val_loss: 0.9888 - val_acc: 0.8043\n",
            "Epoch 97/100\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.1653 - acc: 0.9583 - val_loss: 0.9894 - val_acc: 0.8043\n",
            "Epoch 98/100\n",
            "50000/50000 [==============================] - 23s 463us/step - loss: 0.1680 - acc: 0.9562 - val_loss: 0.9902 - val_acc: 0.8042\n",
            "Epoch 99/100\n",
            "50000/50000 [==============================] - 23s 464us/step - loss: 0.1650 - acc: 0.9576 - val_loss: 0.9912 - val_acc: 0.8042\n",
            "Epoch 100/100\n",
            "50000/50000 [==============================] - 23s 465us/step - loss: 0.1687 - acc: 0.9574 - val_loss: 0.9907 - val_acc: 0.8044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8mip_q3rnWm",
        "colab_type": "text"
      },
      "source": [
        "ついに8割超えた。まだ改善の余地はありそうだ。"
      ]
    }
  ]
}